{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "eTAV6btdD3ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rTDeC_5C2Sbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images and masks\n",
        "def preprocess_image_mask(image_path, mask_path, img_size=(128, 128)):\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
        "\n",
        "    mask = tf.keras.preprocessing.image.load_img(mask_path, target_size=img_size, color_mode=\"grayscale\")\n",
        "    mask = tf.keras.preprocessing.image.img_to_array(mask) / 255.0\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def load_dataset(split, image_folder, mask_folder, img_size=(128, 128)):\n",
        "    images, masks = [], []\n",
        "    img_dir = os.path.join(image_folder, split)\n",
        "    mask_dir = os.path.join(mask_folder, split)\n",
        "\n",
        "    for fname in sorted(os.listdir(img_dir)):\n",
        "        if fname.endswith('.jpg'):\n",
        "            img_path = os.path.join(img_dir, fname)\n",
        "            mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))\n",
        "            if os.path.exists(mask_path):\n",
        "                img, mask = preprocess_image_mask(img_path, mask_path, img_size)\n",
        "                images.append(img)\n",
        "                masks.append(mask)\n",
        "            else:\n",
        "                print(f\"Missing mask for {fname}, skipping.\")\n",
        "    return np.array(images), np.array(masks)"
      ],
      "metadata": {
        "id": "o_PfrRtG2WWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "image_folder = \"/content/gdrive/MyDrive/images\"\n",
        "mask_folder = \"/content/gdrive/MyDrive/annotations\"\n",
        "\n",
        "# Load data\n",
        "X_train, y_train = load_dataset('train', image_folder, mask_folder)\n",
        "X_val, y_val = load_dataset('val', image_folder, mask_folder)\n",
        "X_test, y_test = load_dataset('test', image_folder, mask_folder)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Val: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "3fibBTDNCLRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# U-Net model with enhancements\n",
        "def unet(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    def conv_block(x, filters):\n",
        "        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        return x\n",
        "\n",
        "    c1 = conv_block(inputs, 64)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = conv_block(p1, 128)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = conv_block(p2, 256)\n",
        "\n",
        "    u1 = UpSampling2D((2, 2))(c3)\n",
        "    u1 = concatenate([u1, c2])\n",
        "    c4 = conv_block(u1, 128)\n",
        "\n",
        "    u2 = UpSampling2D((2, 2))(c4)\n",
        "    u2 = concatenate([u2, c1])\n",
        "    c5 = conv_block(u2, 64)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = unet()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=16,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "DV1RM8Ch2zos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred = (y_pred > threshold).astype(np.float32)\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
        "    dice = (2 * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
        "    iou = intersection / (union + 1e-6)\n",
        "    pixel_accuracy = np.sum(y_true == y_pred) / y_true.size\n",
        "    return iou, dice, pixel_accuracy\n",
        "\n",
        "def evaluate_metrics_on_dataset(model, X, y, threshold=0.5):\n",
        "    y_pred = model.predict(X)\n",
        "    metrics = [compute_metrics(y[i], y_pred[i], threshold) for i in range(len(y))]\n",
        "    iou, dice, acc = map(np.mean, zip(*metrics))\n",
        "    print(f\"Mean IoU: {iou:.4f}, Dice: {dice:.4f}, Accuracy: {acc:.4f}\")\n",
        "    return iou, dice, acc\n",
        "\n",
        "evaluate_metrics_on_dataset(model, X_val, y_val)\n",
        "\n",
        "# Visualization\n",
        "def visualize_predictions(model, X, y_true, num_samples=5):\n",
        "    preds = model.predict(X[:num_samples])\n",
        "    for i in range(num_samples):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(X[i])\n",
        "        plt.title(\"Image\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(y_true[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Ground Truth\")\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(preds[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Prediction\")\n",
        "        plt.show()\n",
        "\n",
        "visualize_predictions(model, X_val, y_val)\n"
      ],
      "metadata": {
        "id": "VE1WccllJSU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}